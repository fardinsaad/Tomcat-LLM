{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea83d6a4-dcc2-4186-a7ac-7564c3c55b5d",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "## Reload and import agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46b8d7d-9fd4-47ad-8def-ba20dc20dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY: AIzaSyBOPnH1wBVvY-zqOgkefBn7ef8DrCqtpCg\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import agent\n",
    "importlib.reload(agent)\n",
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7b55b3-3354-4e92-9b4a-1ba899dc70dc",
   "metadata": {},
   "source": [
    "## Reload and import env_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494fbd67-6d1c-4100-aabb-26d7fd721afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import env_setup\n",
    "importlib.reload(env_setup)\n",
    "from env_setup import GridEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36353e34",
   "metadata": {},
   "source": [
    "# Individual Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656505a3-ac38-4d1e-975f-cd13f6793f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . y . . . b W W W W\n",
      "r W W r W W . r W W W g\n",
      "W W W W W W m W W W W R\n",
      "W W W W W W . W W W W .\n",
      "g . . . B . . R . . . .\n",
      "W W W W W W . W W W W W\n",
      "W W W W W W . W W W W W\n",
      ". . . Y . . . W W W W W\n",
      "B W W W W W . W W W W W\n",
      "g W W W W W h . . . . g\n",
      "Generating chain-of-thought prompt...\n",
      "```\n",
      "Human Action: The human moves upward from their current position at (9,6) to (4,6), which is adjacent to the red door at (4,7). Upon arriving at (4,6), they provide the instruction.\n",
      "Instruction: Give me a red key for this door?\n",
      "Type: Clear. The human is adjacent to the red door at (4,7) and requests a red key. This clearly indicates the intention to unlock this specific door and potentially access something beyond it.\n",
      "Response: The human is requesting a red key to unlock the red door at (4,7). There are three red keys available on the grid at (1,0), (1,3), and (1,7). To minimize movement, I will collect the closest red key at (1,0) and pass it to the human at (4,6).\n",
      "Actions:\n",
      "1) Collect: red_key at (1,0).\n",
      "2) Pass: red_key to the human at (4,6).\n",
      "3) Unlock: human unlocks the Red_door at (4,7).\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Initialize the environment and agent\n",
    "env = GridEnvironment()\n",
    "name = \"3.txt\"  # Change this to the name of the grid file you want to load like \"1.txt\", \"2.txt\", etc.\n",
    "grid_file_path = env.get_grid_file_path(name)\n",
    "\n",
    "if grid_file_path:\n",
    "    env.load_grid_from_file(grid_file_path)\n",
    "    env.display_grid()\n",
    "\n",
    "# Get agent and object positions\n",
    "agent_pos = env.get_agent_position()\n",
    "exp = True # True for CP, False for Fs-CoT\n",
    "llm = \"gemma3\"\n",
    "object_pos = env.get_all_object_positions()\n",
    "\n",
    "# Initialize the agent\n",
    "my_agent = Agent(agent_pos)\n",
    "\n",
    "# Provide instructions and test the LLM\n",
    "human_move = \"The human moves upward from their current position at (9,6) to (4,6), which is adjacent to the red door at (4,7). Upon arriving at (4,6), they provide the instruction.\" # Change the human move to test different cases\n",
    "instruction = \"Give me a red key for this door?\" # Change the instruction to test different cases\n",
    "response = my_agent.chain_of_thought_prompt(instruction, env.grid, human_move, object_pos, exp, llm)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d306f",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eb437e",
   "metadata": {},
   "source": [
    "## Experiment 1: Tomcat with CP (GPT-4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file from the local directory\n",
    "csv_file_path = 'ToM_CP-dataset.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "#print(df.head())\n",
    "\n",
    "# Ensure the 'Generated_response_gpt4o' column exists and is of type string\n",
    "if 'Generated_response_gpt4o' not in df.columns:\n",
    "    df['Generated_response_gpt4o'] = \"\"  # Initialize with empty strings\n",
    "else:\n",
    "    df['Generated_response_gpt4o'] = df['Generated_response_gpt4o'].astype(str)\n",
    "\n",
    "# num_rows = 1  # Adjust this to process 5 or 10 rows, or any other number\n",
    "# df_subset = df.head(num_rows)\n",
    "\n",
    "# Loop through each row, read the first and second columns, and generate the response\n",
    "for index, row in df.iterrows():\n",
    "    human = row.iloc[0]\n",
    "    instruction = row.iloc[1]  \n",
    "    file_name = row.iloc[2]   \n",
    "\n",
    "\n",
    "    # Initialize the environment and agent for the single file\n",
    "    env = GridEnvironment()\n",
    "    grid_file_path = env.get_grid_file_path(file_name)\n",
    "\n",
    "    if grid_file_path:\n",
    "        env.load_grid_from_file(grid_file_path)\n",
    "        # env.display_grid()\n",
    "\n",
    "        # Get agent and object positions\n",
    "        agent_pos = env.get_agent_position()\n",
    "        object_pos = env.get_all_object_positions()\n",
    "\n",
    "        # Initialize the agent\n",
    "        my_agent = Agent(agent_pos)\n",
    "        \n",
    "        # Experiment flag\n",
    "        exp = True\n",
    "        #LLM used\n",
    "        llm = \"gpt-4o\"\n",
    "\n",
    "        # Generate the response using the agent and instruction\n",
    "        response = my_agent.chain_of_thought_prompt(instruction, env.grid, human, object_pos, exp, llm)\n",
    "        \n",
    "        # Append the generated response directly into the DataFrame\n",
    "        df.at[index, 'Generated_response_gpt4o'] = str(response)\n",
    "\n",
    "# # After processing the subset, save the updated DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e896d0",
   "metadata": {},
   "source": [
    "## Experiment 2: Tomcat with Fs-CoT (GPT-4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file from the local directory\n",
    "csv_file_path = 'ToM_FsCoT-dataset.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "#print(df.head())\n",
    "\n",
    "# Ensure the 'Generated_response_gpt4o' column exists and is of type string\n",
    "if 'Generated_response_gpt4o' not in df.columns:\n",
    "    df['Generated_response_gpt4o'] = \"\"  # Initialize with empty strings\n",
    "else:\n",
    "    df['Generated_response_gpt4o'] = df['Generated_response_gpt4o'].astype(str)\n",
    "\n",
    "# num_rows = 1  # Adjust this to process 5 or 10 rows, or any other number\n",
    "# df_subset = df.head(num_rows)\n",
    "\n",
    "# Loop through each row, read the first and second columns, and generate the response\n",
    "for index, row in df.iterrows():\n",
    "    human = row.iloc[0]\n",
    "    instruction = row.iloc[1]  \n",
    "    file_name = row.iloc[2]   \n",
    "\n",
    "\n",
    "    # Initialize the environment and agent for the single file\n",
    "    env = GridEnvironment()\n",
    "    grid_file_path = env.get_grid_file_path(file_name)\n",
    "\n",
    "    if grid_file_path:\n",
    "        env.load_grid_from_file(grid_file_path)\n",
    "        # env.display_grid()\n",
    "\n",
    "        # Get agent and object positions\n",
    "        agent_pos = env.get_agent_position()\n",
    "        object_pos = env.get_all_object_positions()\n",
    "\n",
    "        # Initialize the agent\n",
    "        my_agent = Agent(agent_pos)\n",
    "        \n",
    "        # Experiment flag\n",
    "        exp = False\n",
    "        #LLM used\n",
    "        llm = \"gpt-4o\"\n",
    "\n",
    "        # Generate the response using the agent and instruction\n",
    "        response = my_agent.chain_of_thought_prompt(instruction, env.grid, human, object_pos, exp, llm)\n",
    "        \n",
    "        # Append the generated response directly into the DataFrame\n",
    "        df.at[index, 'Generated_response_gpt4o'] = str(response)\n",
    "\n",
    "# # After processing the subset, save the updated DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a4c91",
   "metadata": {},
   "source": [
    "## Experiment 3: Tomcat with CP (Gemma3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264b836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 2 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 4 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 6 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 8 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 10 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 12 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 14 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 16 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 18 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 20 rows...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load the CSV file from the local directory\n",
    "csv_file_path = 'ToM_CP-dataset.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "#print(df.head())\n",
    "\n",
    "# Ensure the 'Generated_response_gemma3' column exists and is of type string\n",
    "if 'Generated_response_gemma3' not in df.columns:\n",
    "    df['Generated_response_gemma3'] = \"\"  # Initialize with empty strings\n",
    "else:\n",
    "    df['Generated_response_gemma3'] = df['Generated_response_gemma3'].astype(str)\n",
    "\n",
    "# num_rows = 3  # Adjust this to process 5 or 10 rows, or any other number\n",
    "# df_subset = df.head(num_rows)\n",
    "\n",
    "batch_size = 2  # Number of rows to process in each batch\n",
    "sleep_time = 60  # Sleep time in seconds between batches\n",
    "counter = 0 \n",
    "\n",
    "# Loop through each row, read the first and second columns, and generate the response\n",
    "for index, row in df.iterrows():\n",
    "    human = row.iloc[0]\n",
    "    instruction = row.iloc[1]  \n",
    "    file_name = row.iloc[2]   \n",
    "\n",
    "\n",
    "    # Initialize the environment and agent for the single file\n",
    "    env = GridEnvironment()\n",
    "    grid_file_path = env.get_grid_file_path(file_name)\n",
    "\n",
    "    if grid_file_path:\n",
    "        env.load_grid_from_file(grid_file_path)\n",
    "        # env.display_grid()\n",
    "\n",
    "        # Get agent and object positions\n",
    "        agent_pos = env.get_agent_position()\n",
    "        object_pos = env.get_all_object_positions()\n",
    "\n",
    "        # Initialize the agent\n",
    "        my_agent = Agent(agent_pos)\n",
    "        \n",
    "        # Experiment flag\n",
    "        exp = True\n",
    "        #LLM used\n",
    "        llm = \"gemma3\"\n",
    "\n",
    "        # Generate the response using the agent and instruction\n",
    "        response = my_agent.chain_of_thought_prompt(instruction, env.grid, human, object_pos, exp, llm)\n",
    "        \n",
    "        # Append the generated response directly into the DataFrame\n",
    "        df.at[index, 'Generated_response_gemma3'] = response\n",
    "        counter += 1\n",
    "        if counter % batch_size == 0:\n",
    "            print(f\"Sleeping for {sleep_time} seconds after {counter} rows...\")\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "\n",
    "# # After processing the subset, save the updated DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba3399c",
   "metadata": {},
   "source": [
    "## Experiment 4: Tomcat with Fs-CoT (Gemma3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2d9773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 2 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 4 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 6 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 8 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 10 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 12 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 14 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 16 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 18 rows...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Sleeping for 60 seconds after 20 rows...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load the CSV file from the local directory\n",
    "csv_file_path = 'ToM_FsCoT-dataset.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "#print(df.head())\n",
    "\n",
    "# Ensure the 'Generated_response_gemma3' column exists and is of type string\n",
    "if 'Generated_response_gemma3' not in df.columns:\n",
    "    df['Generated_response_gemma3'] = \"\"  # Initialize with empty strings\n",
    "else:\n",
    "    df['Generated_response_gemma3'] = df['Generated_response_gemma3'].astype(str)\n",
    "\n",
    "# num_rows = 1  # Adjust this to process 5 or 10 rows, or any other number\n",
    "# df_subset = df.head(num_rows)\n",
    "\n",
    "batch_size = 2  # Number of rows to process in each batch\n",
    "sleep_time = 60  # Sleep time in seconds between batches\n",
    "counter = 0 \n",
    "\n",
    "# Loop through each row, read the first and second columns, and generate the response\n",
    "for index, row in df.iterrows():\n",
    "    human = row.iloc[0]\n",
    "    instruction = row.iloc[1]  \n",
    "    file_name = row.iloc[2]   \n",
    "\n",
    "\n",
    "    # Initialize the environment and agent for the single file\n",
    "    env = GridEnvironment()\n",
    "    grid_file_path = env.get_grid_file_path(file_name)\n",
    "\n",
    "    if grid_file_path:\n",
    "        env.load_grid_from_file(grid_file_path)\n",
    "        # env.display_grid()\n",
    "\n",
    "        # Get agent and object positions\n",
    "        agent_pos = env.get_agent_position()\n",
    "        object_pos = env.get_all_object_positions()\n",
    "\n",
    "        # Initialize the agent\n",
    "        my_agent = Agent(agent_pos)\n",
    "        \n",
    "        # Experiment flag\n",
    "        exp = False\n",
    "        #LLM used\n",
    "        llm = \"gemma3\"\n",
    "\n",
    "        # Generate the response using the agent and instruction\n",
    "        response = my_agent.chain_of_thought_prompt(instruction, env.grid, human, object_pos, exp, llm)\n",
    "        \n",
    "        # Append the generated response directly into the DataFrame\n",
    "        df.at[index, 'Generated_response_gemma3'] = response\n",
    "        \n",
    "        counter += 1\n",
    "        if counter % batch_size == 0:\n",
    "            print(f\"Sleeping for {sleep_time} seconds after {counter} rows...\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "# # After processing the subset, save the updated DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10976a61",
   "metadata": {},
   "source": [
    "## Experiment 5: Tomcat with CP (Deepseek-R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n",
      "Generating chain-of-thought prompt...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import time\n",
    "\n",
    "# Load the CSV file from the local directory\n",
    "csv_file_path = 'ToM_CP-dataset.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "#print(df.head())\n",
    "\n",
    "# Ensure the 'Generated_response_gemma3' column exists and is of type string\n",
    "if 'Generated_response_R1' not in df.columns:\n",
    "    df['Generated_response_R1'] = \"\"  # Initialize with empty strings\n",
    "else:\n",
    "    df['Generated_response_R1'] = df['Generated_response_R1'].astype(str)\n",
    "\n",
    "# num_rows = 3  # Adjust this to process 5 or 10 rows, or any other number\n",
    "# df_subset = df.head(num_rows)\n",
    "\n",
    "batch_size = 2  # Number of rows to process in each batch\n",
    "sleep_time = 60  # Sleep time in seconds between batches\n",
    "counter = 0 \n",
    "\n",
    "# Loop through each row, read the first and second columns, and generate the response\n",
    "for index, row in df.iterrows():\n",
    "    human = row.iloc[0]\n",
    "    instruction = row.iloc[1]  \n",
    "    file_name = row.iloc[2]   \n",
    "\n",
    "\n",
    "    # Initialize the environment and agent for the single file\n",
    "    env = GridEnvironment()\n",
    "    grid_file_path = env.get_grid_file_path(file_name)\n",
    "\n",
    "    if grid_file_path:\n",
    "        env.load_grid_from_file(grid_file_path)\n",
    "        # env.display_grid()\n",
    "\n",
    "        # Get agent and object positions\n",
    "        agent_pos = env.get_agent_position()\n",
    "        object_pos = env.get_all_object_positions()\n",
    "\n",
    "        # Initialize the agent\n",
    "        my_agent = Agent(agent_pos)\n",
    "        \n",
    "        # Experiment flag\n",
    "        exp = True\n",
    "        #LLM used\n",
    "        llm = \"R1\"\n",
    "\n",
    "        # Generate the response using the agent and instruction\n",
    "        response = my_agent.chain_of_thought_prompt(instruction, env.grid, human, object_pos, exp, llm)\n",
    "        \n",
    "        # Append the generated response directly into the DataFrame\n",
    "        df.at[index, 'Generated_response_R1'] = response\n",
    "        # counter += 1\n",
    "        # if counter % batch_size == 0:\n",
    "        #     print(f\"Sleeping for {sleep_time} seconds after {counter} rows...\")\n",
    "        #     time.sleep(sleep_time)\n",
    "        \n",
    "\n",
    "# # After processing the subset, save the updated DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c8f32",
   "metadata": {},
   "source": [
    "## Experiment 6: Tomcat with Fs-Cot (Deepseek-R1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import time\n",
    "\n",
    "# Load the CSV file from the local directory\n",
    "csv_file_path = 'ToM_FsCoT-dataset.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "#print(df.head())\n",
    "\n",
    "# Ensure the 'Generated_response_gemma3' column exists and is of type string\n",
    "if 'Generated_response_R1' not in df.columns:\n",
    "    df['Generated_response_R1'] = \"\"  # Initialize with empty strings\n",
    "else:\n",
    "    df['Generated_response_R1'] = df['Generated_response_R1'].astype(str)\n",
    "\n",
    "# num_rows = 3  # Adjust this to process 5 or 10 rows, or any other number\n",
    "# df_subset = df.head(num_rows)\n",
    "\n",
    "batch_size = 2  # Number of rows to process in each batch\n",
    "sleep_time = 60  # Sleep time in seconds between batches\n",
    "counter = 0 \n",
    "\n",
    "# Loop through each row, read the first and second columns, and generate the response\n",
    "for index, row in df.iterrows():\n",
    "    human = row.iloc[0]\n",
    "    instruction = row.iloc[1]  \n",
    "    file_name = row.iloc[2]   \n",
    "\n",
    "\n",
    "    # Initialize the environment and agent for the single file\n",
    "    env = GridEnvironment()\n",
    "    grid_file_path = env.get_grid_file_path(file_name)\n",
    "\n",
    "    if grid_file_path:\n",
    "        env.load_grid_from_file(grid_file_path)\n",
    "        # env.display_grid()\n",
    "\n",
    "        # Get agent and object positions\n",
    "        agent_pos = env.get_agent_position()\n",
    "        object_pos = env.get_all_object_positions()\n",
    "\n",
    "        # Initialize the agent\n",
    "        my_agent = Agent(agent_pos)\n",
    "        \n",
    "        # Experiment flag\n",
    "        exp = False\n",
    "        #LLM used\n",
    "        llm = \"R1\"\n",
    "\n",
    "        # Generate the response using the agent and instruction\n",
    "        response = my_agent.chain_of_thought_prompt(instruction, env.grid, human, object_pos, exp, llm)\n",
    "        \n",
    "        # Append the generated response directly into the DataFrame\n",
    "        df.at[index, 'Generated_response_R1'] = response\n",
    "        counter += 1\n",
    "        print(f\"Counter: {counter}\")\n",
    "        # if counter % batch_size == 0:\n",
    "        #     print(f\"Sleeping for {sleep_time} seconds after {counter} rows...\")\n",
    "        #     time.sleep(sleep_time)\n",
    "        \n",
    "\n",
    "# # After processing the subset, save the updated DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
